{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXZ5gCVaRjYa"
   },
   "source": [
    "# 1. Preliminaries\n",
    "## This is how it all started ...\n",
    "- Rakesh Agrawal, Tomasz Imielinski, Arun N. Swami: Mining Association Rules between Sets of Items in Large Databases. SIGMOD Conference 1993: 207-216\n",
    "- Rakesh Agrawal, Ramakrishnan Srikant: Fast Algorithms for Mining Association Rules in Large Databases. VLDB 1994: 487-499\n",
    "\n",
    "**These two papers are credited with the birth of Data Mining**\n",
    "## Frequent itemset mining (FIM)\n",
    "\n",
    "Find combinations of items (itemsets) that occur frequently.\n",
    "## Applications\n",
    "- Items = products, transactions = sets of products someone bought in one trip to the store.\n",
    "$\\Rightarrow$ items people frequently buy together.\n",
    "    + Example: if people usually buy bread and coffee together, we run a sale of bread to attract people attention and raise price of coffee.\n",
    "- Items = webpages, transactions = words. Unusual words appearing together in a large number of documents, e.g., “Brad” and “Angelina,” may indicate an interesting relationship.\n",
    "- Transactions = Sentences, Items = Documents containing those sentences. Items that appear together too often could represent plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8vAJ8A2RjYi"
   },
   "source": [
    "## Transactional Database\n",
    "A transactional database $D$ consists of $N$ transactions: $D=\\left\\{T_1,T_2,...,T_N\\right\\}$. A transaction $T_n \\in D (1 \\le n \\le N)$ contains one or more items and that $I= \\left\\{ i_1,i_2,…,i_M \\right\\}$ is the set of distinct items in $D$, $T_n \\subset I$. Commonly, a transactional database is represented by a flat file instead of a database system: items are non-negative integers, each row represents a transaction, items in a transaction separated by space.\n",
    "\n",
    "Example: \n",
    "\n",
    "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \n",
    "\n",
    "30 31 32 \n",
    "\n",
    "33 34 35 \n",
    "\n",
    "36 37 38 39 40 41 42 43 44 45 46 \n",
    "\n",
    "38 39 47 48 \n",
    "\n",
    "38 39 48 49 50 51 52 53 54 55 56 57 58 \n",
    "\n",
    "32 41 59 60 61 62 \n",
    "\n",
    "3 39 48 \n",
    "\n",
    "63 64 65 66 67 68 \n",
    "\n",
    "\n",
    "\n",
    "# Definition\n",
    "\n",
    "- Itemset: A collection of one or more items.\n",
    "    + Example: {1 4 5}\n",
    "- **k-itemset**: An itemset that contains k items.\n",
    "- Support: Frequency of occurrence of an itemset.\n",
    "    + Example: From the example above, item 3 appear in 2 transactions so its support is 2.\n",
    "- Frequent itemset: An itemset whose support is greater than or equal to a `minsup` threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdykKxr6RjY-"
   },
   "source": [
    "# The Apriori Principle\n",
    "- If an itemset is frequent, then all of its subsets must also be frequent.\n",
    "- If an itemset is not frequent, then all of its supersets cannot be frequent.\n",
    "- The support of an itemset never exceeds the support of its subsets.\n",
    "$$ \\forall{X,Y}: (X \\subseteq Y) \\Rightarrow s(X)\\ge s(Y)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvfMR7-CRjZB"
   },
   "source": [
    "# 2. Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9gZh4DORjZD"
   },
   "source": [
    "## The Apriori algorithm\n",
    "Suppose:\n",
    "\n",
    "$C_k$ candidate itemsets of size k.\n",
    "\n",
    "$L_k$ frequent itemsets of size k.\n",
    "\n",
    "The level-wise approach of Apriori algorithm can be descibed as follow:\n",
    "1. k=1, $C_k$ = all items.\n",
    "2. While $C_k$ not empty:\n",
    "    3. Scan the database to find which itemsets in $C_k$ are frequent and put them into $L_k$.\n",
    "    4. Use $L_k$ to generate a collection of candidate itemsets $C_{k+1}$ of size k+1.\n",
    "    5. k=k+1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF9xHOBLRjZJ"
   },
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7F0lUOSuRjZN"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OogwdcLRjZf"
   },
   "source": [
    "### Read data\n",
    "First we have to read data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2bsGrTERjZg"
   },
   "outputs": [],
   "source": [
    "\n",
    "def readData(path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------------------\n",
    "        path: path of database D.\n",
    "         \n",
    "    --------------------------\n",
    "    Returns\n",
    "        data: a dictionary for representing database D\n",
    "                 - keys: transaction tids\n",
    "                 - values: itemsets.\n",
    "        s: support of distict items in D.\n",
    "    \"\"\"\n",
    "    data={}\n",
    "    s=defaultdict(lambda: 0) # Initialize a dictionary for storing support of items in I.  \n",
    "    with open(path,'rt') as f:\n",
    "        tid=1\n",
    "        for line in f:\n",
    "            itemset=set(map(int,line.split())) # a python set is a native way for storing an itemset.\n",
    "            for item in itemset:  \n",
    "                s[item]+=1     #Why don't we compute support of items while reading data?\n",
    "            data[tid]= itemset\n",
    "            tid+=1\n",
    "    \n",
    "    return data, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSTC78WURjZu"
   },
   "source": [
    "### Tree Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGAkmuXtRjZw"
   },
   "source": [
    "**I gave you pseudo code of Apriori algorithm above but we implement Tree Projection. Tell me the differences of two algorithms.**\n",
    "\n",
    "\n",
    "**TODO:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BVRT5BnWRjZz"
   },
   "outputs": [],
   "source": [
    "def joinset(a, b):\n",
    "    '''\n",
    "    Parameters\n",
    "    -------------------\n",
    "        2 itemsets a and b (of course they are at same branch in search space)\n",
    "\n",
    "    -------------------\n",
    "    return\n",
    "        ret: itemset generated by joining a and b\n",
    "    '''\n",
    "    # TODO (hint: this function will be called in generateSearchSpace method.):\n",
    "    ret = set(a)\n",
    "    ret.update(set(b))\n",
    "    return ret\n",
    "\n",
    "class TP:\n",
    "    def __init__(self, data=None, s=None, minSup=None):\n",
    "        self.data = data\n",
    "        self.s = {}\n",
    "\n",
    "        for key, support in sorted(s.items(), key=lambda item: item[1]):\n",
    "            self.s[key] = support\n",
    "        # TODO: why should we do this, answer it at the markdown below?\n",
    "\n",
    "        self.minSup = minSup\n",
    "        self.L = {}  # Store frequent itemsets mined from database\n",
    "        self.runAlgorithm()\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Initialize search space at first step\n",
    "        --------------------------------------\n",
    "        We represent our search space in a tree structure\n",
    "        \"\"\"\n",
    "        tree = {}\n",
    "\n",
    "        search_space = {}\n",
    "        for item, support in self.s.items():\n",
    "            search_space[item] = {}\n",
    "\n",
    "            search_space[item]['itemset'] = [item]\n",
    "            ''' \n",
    "            python set does not remain elements order\n",
    "            so we use a list to extend it easily when create new itemset \n",
    "            but why we store itemset in data by a python set???? '''\n",
    "            # TODO: study about python set and its advantages,\n",
    "            # answer at the markdown below.\n",
    "\n",
    "            search_space[item]['pruned'] = False\n",
    "            # TODO:\n",
    "            # After finish implementing the algorithm tell me why should you use this\n",
    "            # instead of delete item directly from search_space and tree.\n",
    "\n",
    "            search_space[item]['support'] = support\n",
    "\n",
    "            tree[item] = {}\n",
    "            '''\n",
    "            Why should i store an additional tree (here it called tree)? \n",
    "            Answer: This really help in next steps.\n",
    "\n",
    "            Remember that there is always a big gap from theory to practicality\n",
    "            and implementing this algorithm in python is not as simple as you think.\n",
    "            '''\n",
    "\n",
    "        return tree, search_space\n",
    "\n",
    "    def computeItemsetSupport(self, itemset):\n",
    "\n",
    "        '''Return support of itemset'''\n",
    "        # TODO (hint: this is why i use python set in data)\n",
    "        support = 0\n",
    "        for transaction in self.data.values():\n",
    "            if itemset.issubset(transaction):\n",
    "                support += 1\n",
    "        return support\n",
    "\n",
    "    def get_sub_tree(self, k, tree, search_space, itter_node):\n",
    "        if k == 0:\n",
    "            return search_space[itter_node]['support']\n",
    "        subtree = search_space[itter_node]\n",
    "        for node in subtree.keys():\n",
    "            k-=1\n",
    "            self.get_sub_tree(k,tree,search_space,node)\n",
    "\n",
    "\n",
    "    def prune(self, k, tree, search_space):\n",
    "\n",
    "        '''\n",
    "        In this method we will find out which itemset in current search space is frequent\n",
    "        itemset then add it to L[k]. In addition, we prune those are not frequent itemsets.\n",
    "        '''\n",
    "        if self.L.get(k) is None: self.L[k] = []\n",
    "        # TODO\n",
    "        frequent_itemsets = [] # list to contain freq ietmsets\n",
    "        \n",
    "        for each in list(tree.keys()):\n",
    "            # check if support meets the minsup or not\n",
    "            if search_space[each]['support']<self.minSup:\n",
    "                search_space[each][\"pruned\"] = True \n",
    "            else: \n",
    "                frequent_itemsets.append(sorted(search_space[each][\"itemset\"]))\n",
    "                search_space[each][\"pruned\"] = False\n",
    "\n",
    "        # add freq itemsets into L[k]\n",
    "        self.L.setdefault(k, []).extend(frequent_itemsets)\n",
    "\n",
    "    def generateSearchSpace(self, k, tree, search_space):\n",
    "        '''\n",
    "        Generate search space for exploring k+1 itemset. (Recursive function)\n",
    "        '''\n",
    "        items = list(tree.keys())\n",
    "        ''' print search_space.keys() you will understand  \n",
    "         why we need an additional tree, '''\n",
    "        l = len(items)\n",
    "        self.prune(k, tree, search_space)\n",
    "        if l == 0: return  # Stop condition\n",
    "        for i in range(l - 1):\n",
    "            sub_search_space = {}\n",
    "            sub_tree = {}\n",
    "            a = items[i]\n",
    "            if search_space[a]['pruned']: continue\n",
    "\n",
    "            for j in range(i + 1, l):\n",
    "                b = items[j]\n",
    "                search_space[a][b] = {}\n",
    "                tree[a][b] = {}\n",
    "                # You really need to understand what am i doing here before doing work below.\n",
    "                # (Hint: draw tree and search space to draft).\n",
    "\n",
    "                # TODO:\n",
    "                # First create newset using join set\n",
    "                newset = joinset(search_space[a][\"itemset\"], search_space[b][\"itemset\"])\n",
    "                \n",
    "                # Second add newset to search_space\n",
    "                search_space[a][b][\"itemset\"] = newset\n",
    "                search_space[a][b][\"support\"] = self.computeItemsetSupport(newset)\n",
    "            \n",
    "            sub_tree = tree[a].copy()\n",
    "            sub_search_space = search_space[a].copy()  \n",
    "            \n",
    "            #  Generate search_space for k+1-itemset\n",
    "            self.generateSearchSpace(k + 1, sub_tree, sub_search_space)\n",
    "\n",
    "    def runAlgorithm(self):\n",
    "        tree, search_space = self.initialize()  # generate search space for 1-itemset\n",
    "        self.generateSearchSpace(1, tree, search_space)\n",
    "\n",
    "    def miningResults(self):\n",
    "        return self.L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tMTpwxLRjZ-"
   },
   "source": [
    "Ok, let's test on a typical dataset `chess`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gLygYqiYRjZ-"
   },
   "outputs": [],
   "source": [
    "data, s= readData('chess.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnxbU77YRjaF",
    "outputId": "c3b158be-6b46-4a3c-9b71-6a92d3d31ded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [[48], [56], [66], [34], [62], [7], [36], [60], [40], [29], [52], [58]], 2: [[48, 52], [48, 58], [29, 56], [52, 56], [56, 58], [60, 66], [29, 66], [52, 66], [58, 66], [34, 40], [29, 34], [34, 52], [34, 58], [60, 62], [40, 62], [29, 62], [52, 62], [58, 62], [7, 60], [7, 40], [7, 29], [7, 52], [7, 58], [36, 60], [36, 40], [29, 36], [36, 52], [36, 58], [40, 60], [29, 60], [52, 60], [58, 60], [29, 40], [40, 52], [40, 58], [29, 52], [29, 58], [52, 58]], 3: [[48, 52, 58], [29, 52, 56], [29, 56, 58], [52, 56, 58], [29, 60, 66], [52, 60, 66], [58, 60, 66], [29, 52, 66], [29, 58, 66], [52, 58, 66], [29, 34, 40], [34, 40, 52], [34, 40, 58], [29, 34, 52], [29, 34, 58], [34, 52, 58], [29, 60, 62], [52, 60, 62], [58, 60, 62], [29, 40, 62], [40, 52, 62], [40, 58, 62], [29, 52, 62], [29, 58, 62], [52, 58, 62], [7, 40, 60], [7, 29, 60], [7, 52, 60], [7, 58, 60], [7, 29, 40], [7, 40, 52], [7, 40, 58], [7, 29, 52], [7, 29, 58], [7, 52, 58], [36, 40, 60], [29, 36, 60], [36, 52, 60], [36, 58, 60], [29, 36, 40], [36, 40, 52], [36, 40, 58], [29, 36, 52], [29, 36, 58], [36, 52, 58], [29, 40, 60], [40, 52, 60], [40, 58, 60], [29, 52, 60], [29, 58, 60], [52, 58, 60], [29, 40, 52], [29, 40, 58], [40, 52, 58], [29, 52, 58]], 4: [[29, 52, 56, 58], [29, 52, 60, 66], [29, 58, 60, 66], [52, 58, 60, 66], [29, 52, 58, 66], [29, 34, 40, 52], [29, 34, 40, 58], [34, 40, 52, 58], [29, 34, 52, 58], [29, 58, 60, 62], [52, 58, 60, 62], [29, 40, 52, 62], [29, 40, 58, 62], [40, 52, 58, 62], [29, 52, 58, 62], [7, 40, 58, 60], [7, 29, 52, 60], [7, 29, 58, 60], [7, 52, 58, 60], [7, 29, 40, 52], [7, 29, 40, 58], [7, 40, 52, 58], [7, 29, 52, 58], [29, 36, 40, 60], [36, 40, 52, 60], [36, 40, 58, 60], [29, 36, 52, 60], [29, 36, 58, 60], [36, 52, 58, 60], [29, 36, 40, 52], [29, 36, 40, 58], [36, 40, 52, 58], [29, 36, 52, 58], [29, 40, 52, 60], [29, 40, 58, 60], [40, 52, 58, 60], [29, 52, 58, 60], [29, 40, 52, 58]], 5: [[29, 52, 58, 60, 66], [29, 34, 40, 52, 58], [29, 40, 52, 58, 62], [7, 29, 52, 58, 60], [7, 29, 40, 52, 58], [29, 36, 40, 52, 60], [29, 36, 40, 58, 60], [36, 40, 52, 58, 60], [29, 36, 52, 58, 60], [29, 36, 40, 52, 58], [29, 40, 52, 58, 60]], 6: [[29, 36, 40, 52, 58, 60]]}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "a=TP(data=data,s=s, minSup=3000)\n",
    "print(a.miningResults())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp0RFbw-RjaU"
   },
   "source": [
    "### Answer questions here:\n",
    "**Why don't we compute support of items while reading data?**\n",
    "- Computing support from the beginning may increase time and computing resources during the data reading process. \n",
    "\n",
    "- Calculating the support of items during the initialization of the TP class is a way to sort items according to increasing support. If we just read the data directly, compute support and then arrange them, it will be relatively complicated and resource-consuming. Additionally, separating data reading and TP layer initialization makes the code more readable and maintainable, and provides flexibility for algorithm implementation.\n",
    "\n",
    "**why should we do sort**\n",
    "- In Tree Projection algorithm, constructing candidate items based on items with higher support can help reduce the number of items to be examined during the generation of candidate items. By focusing on items with higher support, we can skip over items with lower likelihood of becoming candidate items.\n",
    "\n",
    "- Sorting items in ascending order of support can also optimize the data traversal process. By traversing items in this order, we can early eliminate items that do not meet the minimum support threshold without the need for further examination. This helps save time and computational resources, improving the algorithm's efficiency.\n",
    "\n",
    "- Furthermore, minimizing the use of temporary memory resources is another significant advantage of sorting items in ascending order of support. This allows for more efficient management of memory resources and avoids memory overload situations.\n",
    "\n",
    "\n",
    "**study about python set and its advantages ?**\n",
    "- Python set ensure that each element appears only once. This will help ensure data integrity by ensuring uniqueness of element sets\n",
    "- By using an internal hash table, Python set could determine whether a set of elements is a subset of a transaction in the database or not can be done quickly.\n",
    "- Storing sets of elements as Python set allows the use of set operations such as intersection, union, and complement. These operations can be useful for many data mining tasks, helping to identify frequent sets of elements and association rules.\n",
    "\n",
    "- In short, Python set provide a flexible and efficient way to work with collections of unique elements, provide fast existence checking, and are compatible with set operations. consistency and integrity of data. These benefits contribute to the performance and reliability of mining algorithms.\n",
    "\n",
    "**After finish implementing the algorithm tell me why should you use this? Instead of delete item directly from search_space and tree.**\n",
    "- By using the markup mechanism, we retain the original data structure of search_space and tree. This means that these data structures still contain information about all the items and the relationships between them, but only mark those items that have been removed.\n",
    "\n",
    "- When we need to check or perform other operations on search_space and tree, we can easily identify purged items by checking the pruned status.\n",
    "\n",
    "- Instead of deleting elements from search_space and tree, marking only requires changing a boolean value. This saves time and resources compared to deleting and restructuring data structures.\n",
    "\n",
    "**Apriori algorithm and Tree Projection, tell me the differences of two algorithms.**\n",
    "\n",
    "- **Apriori algorithm:**\n",
    "    - The apriori algorithm uses the method of generating all candidate sets and testing the popularity of candidate sets to find common sets.\n",
    "    - This algorithm often uses simple data structures such as tables to store candidate sets and frequent itemsets.\n",
    "    - Apriori algorithms have a performance disadvantage when working with large data sets, this is because it have to generate a very large number of candidate sets and test them. However, this algorithm still works well and is quite easy to implement.\n",
    "\n",
    "- **Tree Projection:**\n",
    "    - Tree projection does not generate candidate sets, it relies on the tree structure to eliminate uncommon subsets and only focuses on finding potential branches.\n",
    "    - This algorithm uses tree structures or similar graphs to store the structure of data and find information about frequent itemsets.\n",
    "    - Tree Projection can overcome the shortcomings of Apriori when working with large data sets because it does not need to generate candidate sets, it can be said that this algorithm has better performance than Apriori.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnVm8wYIRjaV"
   },
   "source": [
    "# 3. Churn analysis\n",
    "\n",
    "In this section, you will use frequent itemset mining technique to analyze `churn` dataset (for any purposes). \n",
    "\n",
    "*Remember this dataset is not represented as a transactional database, first thing that you have to do is transforming it into a flat file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Brief about the idea:**\n",
    "- I'm gonna use `Tree Projection` to find frequent itemset in the subdataset which **Churn is True** and the subdataset which **Churn is False**.\n",
    "\n",
    "    - Firstly, we should discretize the numerical attributes and standardize it to facilitate analysis.\n",
    "\n",
    "    - Then, we will split the dataset into 2 subsets based on the `Churn` value and transform it into transaction data.\n",
    "\n",
    "    - Finally, use Tree Projection to find frequent itemsets in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# YOUR CODE HERE\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "def transform_to_flat(input_df, frequent_items=None):\n",
    "    flat_dict = {}\n",
    "    for idx, row in input_df.iterrows():\n",
    "        transaction_dict = {}\n",
    "        for col, value in row.iloc[:-1].items():  # remove last col\n",
    "            transaction_dict[f\"{col} : {value}\"] = 1  \n",
    "        if frequent_items:\n",
    "            transaction_dict.update(frequent_items.get(idx, {}))\n",
    "        flat_dict[idx] = transaction_dict\n",
    "    return flat_dict\n",
    "\n",
    "def compute_frequencies(data):\n",
    "    s = Counter()\n",
    "    for each in data.values():\n",
    "        s.update(each)\n",
    "    return dict(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'churn.txt'\n",
    "df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing - Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data have no duplicated line!\n"
     ]
    }
   ],
   "source": [
    "# retrieve the index\n",
    "index = df.index\n",
    "# create a Pandas Series indicating whether each index is duplicated or not\n",
    "deDupSeries = index.duplicated(keep='first')\n",
    "# calculate the number of duplicated rows\n",
    "num_duplicated_rows = deDupSeries.sum()\n",
    "\n",
    "if num_duplicated_rows == 0:\n",
    "    print(f\"Raw data have no duplicated line!\")\n",
    "else:\n",
    "    ext = \"lines\" if num_duplicated_rows > 1 else \"line\"\n",
    "    print(f\"Raw data have {num_duplicated_rows} duplicated \" + ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missing_ratio</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lower_quartile</th>\n",
       "      <td>74.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>24.43</td>\n",
       "      <td>166.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>14.16</td>\n",
       "      <td>167.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>7.52</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>101.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.4</td>\n",
       "      <td>101.0</td>\n",
       "      <td>30.50</td>\n",
       "      <td>201.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17.12</td>\n",
       "      <td>201.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.05</td>\n",
       "      <td>10.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upper_quartile</th>\n",
       "      <td>127.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>216.4</td>\n",
       "      <td>114.0</td>\n",
       "      <td>36.79</td>\n",
       "      <td>235.3</td>\n",
       "      <td>114.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>235.3</td>\n",
       "      <td>113.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>12.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>350.8</td>\n",
       "      <td>165.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>363.7</td>\n",
       "      <td>170.0</td>\n",
       "      <td>30.91</td>\n",
       "      <td>395.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>17.77</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Account Length  Area Code  VMail Message  Day Mins  Day Calls  \\\n",
       "missing_ratio              0.0        0.0            0.0       0.0        0.0   \n",
       "min                        1.0      408.0            0.0       0.0        0.0   \n",
       "lower_quartile            74.0      408.0            0.0     143.7       87.0   \n",
       "median                   101.0      415.0            0.0     179.4      101.0   \n",
       "upper_quartile           127.0      510.0           20.0     216.4      114.0   \n",
       "max                      243.0      510.0           51.0     350.8      165.0   \n",
       "\n",
       "                Day Charge  Eve Mins  Eve Calls  Eve Charge  Night Mins  \\\n",
       "missing_ratio         0.00       0.0        0.0        0.00         0.0   \n",
       "min                   0.00       0.0        0.0        0.00        23.2   \n",
       "lower_quartile       24.43     166.6       87.0       14.16       167.0   \n",
       "median               30.50     201.4      100.0       17.12       201.2   \n",
       "upper_quartile       36.79     235.3      114.0       20.00       235.3   \n",
       "max                  59.64     363.7      170.0       30.91       395.0   \n",
       "\n",
       "                Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
       "missing_ratio           0.0          0.00        0.0         0.0         0.00   \n",
       "min                    33.0          1.04        0.0         0.0         0.00   \n",
       "lower_quartile         87.0          7.52        8.5         3.0         2.30   \n",
       "median                100.0          9.05       10.3         4.0         2.78   \n",
       "upper_quartile        113.0         10.59       12.1         6.0         3.27   \n",
       "max                   175.0         17.77       20.0        20.0         5.40   \n",
       "\n",
       "                CustServ Calls  \n",
       "missing_ratio              0.0  \n",
       "min                        0.0  \n",
       "lower_quartile             1.0  \n",
       "median                     1.0  \n",
       "upper_quartile             2.0  \n",
       "max                        9.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col_info_df = df.select_dtypes(exclude=['object', 'bool'])\n",
    "\n",
    "def missing_ratio(s):\n",
    "    return (s.isna().mean() * 100)\n",
    "\n",
    "def median(df):\n",
    "    return (df.quantile(0.5))\n",
    "\n",
    "def lower_quartile(df):\n",
    "    return (df.quantile(0.25))\n",
    "\n",
    "def upper_quartile(df):\n",
    "    return (df.quantile(0.75))\n",
    "\n",
    "num_col_info_df = num_col_info_df.agg([missing_ratio, \"min\", lower_quartile, median, upper_quartile, \"max\"])\n",
    "num_col_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missing_ratio</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_values</th>\n",
       "      <td>51</td>\n",
       "      <td>3333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value_ratios</th>\n",
       "      <td>{'WV': 3.2, 'MN': 2.5, 'NY': 2.5, 'AL': 2.4, '...</td>\n",
       "      <td>{'382-4657': 0.0, '348-7071': 0.0, '389-6082':...</td>\n",
       "      <td>{'no': 90.3, 'yes': 9.7}</td>\n",
       "      <td>{'no': 72.3, 'yes': 27.7}</td>\n",
       "      <td>{'False.': 85.5, 'True.': 14.5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           State  \\\n",
       "missing_ratio                                                0.0   \n",
       "num_values                                                    51   \n",
       "value_ratios   {'WV': 3.2, 'MN': 2.5, 'NY': 2.5, 'AL': 2.4, '...   \n",
       "\n",
       "                                                           Phone  \\\n",
       "missing_ratio                                                0.0   \n",
       "num_values                                                  3333   \n",
       "value_ratios   {'382-4657': 0.0, '348-7071': 0.0, '389-6082':...   \n",
       "\n",
       "                             Int'l Plan                 VMail Plan  \\\n",
       "missing_ratio                       0.0                        0.0   \n",
       "num_values                            2                          2   \n",
       "value_ratios   {'no': 90.3, 'yes': 9.7}  {'no': 72.3, 'yes': 27.7}   \n",
       "\n",
       "                                        Churn?  \n",
       "missing_ratio                              0.0  \n",
       "num_values                                   2  \n",
       "value_ratios   {'False.': 85.5, 'True.': 14.5}  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col_info_df = df.select_dtypes(include=['object', 'bool'])\n",
    "\n",
    "def missing_ratio(s):\n",
    "    return (s.isna().mean() * 100)\n",
    "\n",
    "def num_values(s):\n",
    "    s = s.astype('str').str.split(';')\n",
    "    s = s.explode()\n",
    "    return len(s.value_counts())\n",
    "\n",
    "def value_ratios(s):\n",
    "    s = s.astype('str').str.split(';')\n",
    "    s = s.explode()\n",
    "    totalCount = (~s.isna()).sum()\n",
    "    return ((s.value_counts()/totalCount*100).round(1)).to_dict()\n",
    "\n",
    "cat_col_info_df = cat_col_info_df.agg([missing_ratio, num_values, value_ratios])\n",
    "cat_col_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I assumed that `Phone` columns is meaningless in this situation, so i'll drop it.**\n",
    "\n",
    "- **Although the `VMail Plan` and `VMail Message` columns are two attributes, they have related meanings. If `VMail Plan` = no, then `VMail Message` = 0 and if `VMail Plan` is yes, then `VMail Message` > 0, so I will drop the column `VMail Plan`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Phone','VMail Plan'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Okay then, our data have no missing values as well as duplicate rows. Now, I will discrete and normalized the numerical columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.78</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>408</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>AZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>WV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>RI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.64</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>CT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>510</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>TN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.85</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.86</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Account Length  Area Code Int'l Plan  VMail Message  Day Mins  \\\n",
       "0       KS             2.0        415         no             25       2.0   \n",
       "1       OH             1.0        415         no             26       1.0   \n",
       "2       NJ             2.0        415         no              0       2.0   \n",
       "3       OH             1.0        408        yes              0       2.0   \n",
       "4       OK             0.0        415        yes              0       1.0   \n",
       "...    ...             ...        ...        ...            ...       ...   \n",
       "3328    AZ             2.0        415         no             36       1.0   \n",
       "3329    WV             0.0        415         no              0       2.0   \n",
       "3330    RI             0.0        510         no              0       1.0   \n",
       "3331    CT             2.0        510        yes              0       2.0   \n",
       "3332    TN             0.0        415         no             25       2.0   \n",
       "\n",
       "      Day Calls  Day Charge  Eve Mins  Eve Calls  Eve Charge  Night Mins  \\\n",
       "0           2.0       45.07       1.0        1.0       16.78         2.0   \n",
       "1           2.0       27.47       1.0        1.0       16.62         2.0   \n",
       "2           2.0       41.38       0.0        2.0       10.30         0.0   \n",
       "3           0.0       50.90       0.0        0.0        5.26         1.0   \n",
       "4           2.0       28.34       0.0        2.0       12.61         1.0   \n",
       "...         ...         ...       ...        ...         ...         ...   \n",
       "3328        0.0       26.55       1.0        2.0       18.32         2.0   \n",
       "3329        0.0       39.29       0.0        0.0       13.04         1.0   \n",
       "3330        2.0       30.74       2.0        0.0       24.55         1.0   \n",
       "3331        1.0       36.35       0.0        0.0       13.57         0.0   \n",
       "3332        2.0       39.85       2.0        0.0       22.60         2.0   \n",
       "\n",
       "      Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
       "0             0.0         11.01        1.0         1.0         2.70   \n",
       "1             1.0         11.45        2.0         1.0         3.70   \n",
       "2             1.0          7.32        2.0         2.0         3.29   \n",
       "3             0.0          8.86        0.0         2.0         1.78   \n",
       "4             2.0          8.41        1.0         1.0         2.73   \n",
       "...           ...           ...        ...         ...          ...   \n",
       "3328          0.0         12.56        1.0         2.0         2.67   \n",
       "3329          2.0          8.61        1.0         1.0         2.59   \n",
       "3330          0.0          8.64        2.0         2.0         3.81   \n",
       "3331          2.0          6.26        0.0         2.0         1.35   \n",
       "3332          0.0         10.86        2.0         1.0         3.70   \n",
       "\n",
       "      CustServ Calls  Churn?  \n",
       "0                1.0  False.  \n",
       "1                1.0  False.  \n",
       "2                0.0  False.  \n",
       "3                2.0  False.  \n",
       "4                2.0  False.  \n",
       "...              ...     ...  \n",
       "3328             2.0  False.  \n",
       "3329             2.0  False.  \n",
       "3330             2.0  False.  \n",
       "3331             2.0  False.  \n",
       "3332             0.0  False.  \n",
       "\n",
       "[3333 rows x 19 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we gonna discrete it into 3 bins, as 0,1,2 represent for low, medium and high.\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "df_discretized = pd.DataFrame(discretizer.fit_transform(df[['Account Length', 'Day Mins', 'Day Calls', 'Eve Mins', 'Eve Calls', 'Night Mins', 'Night Calls', 'Intl Mins', 'Intl Calls', 'CustServ Calls']]),\n",
    "                               columns=['Account Length', 'Day Mins', 'Day Calls', 'Eve Mins', 'Eve Calls', 'Night Mins', 'Night Calls', 'Intl Mins', 'Intl Calls', 'CustServ Calls'])\n",
    "\n",
    "# concatenate it into original df\n",
    "df[['Account Length', 'Day Mins', 'Day Calls', 'Eve Mins', 'Eve Calls', 'Night Mins', 'Night Calls', 'Intl Mins', 'Intl Calls', 'CustServ Calls']] = df_discretized\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into 2 subdataset and transform into flat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 2 subdataset and transform into flat file\n",
    "transaction_churn_true = transform_to_flat(df[df['Churn?'] == 'True.'])\n",
    "transaction_churn_false = transform_to_flat(df[df['Churn?'] == 'False.'])\n",
    "\n",
    "# compute frequencies\n",
    "freq_true = compute_frequencies(transaction_churn_true)\n",
    "freq_false = compute_frequencies(transaction_churn_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tree Project to find Frequent Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.35 # 35% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - ['Eve Calls : 2.0']\n",
      "1 - ['Intl Calls : 1.0']\n",
      "1 - ['Day Calls : 2.0']\n",
      "1 - ['Intl Mins : 2.0']\n",
      "1 - ['Eve Mins : 2.0']\n",
      "1 - ['Area Code : 415']\n",
      "1 - ['Day Mins : 2.0']\n",
      "1 - ['CustServ Calls : 2.0']\n",
      "1 - [\"Int'l Plan : no\"]\n",
      "1 - ['VMail Message : 0']\n",
      "2 - ['Eve Mins : 2.0', 'VMail Message : 0']\n",
      "2 - ['Area Code : 415', \"Int'l Plan : no\"]\n",
      "2 - ['Area Code : 415', 'VMail Message : 0']\n",
      "2 - ['Day Mins : 2.0', \"Int'l Plan : no\"]\n",
      "2 - ['Day Mins : 2.0', 'VMail Message : 0']\n",
      "2 - ['CustServ Calls : 2.0', \"Int'l Plan : no\"]\n",
      "2 - ['CustServ Calls : 2.0', 'VMail Message : 0']\n",
      "2 - [\"Int'l Plan : no\", 'VMail Message : 0']\n",
      "3 - ['Day Mins : 2.0', \"Int'l Plan : no\", 'VMail Message : 0']\n",
      "3 - ['CustServ Calls : 2.0', \"Int'l Plan : no\", 'VMail Message : 0']\n"
     ]
    }
   ],
   "source": [
    "true = TP(data=transaction_churn_true,s=freq_true,minSup=len(transaction_churn_true)*threshold)\n",
    "for (level, sub_list) in true.miningResults().items():\n",
    "    for each in sub_list:\n",
    "        print(f\"{level} - {each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - ['Day Mins : 1.0']\n",
      "1 - ['CustServ Calls : 1.0']\n",
      "1 - ['Intl Calls : 1.0']\n",
      "1 - ['CustServ Calls : 2.0']\n",
      "1 - ['Intl Calls : 2.0']\n",
      "1 - ['Area Code : 415']\n",
      "1 - ['VMail Message : 0']\n",
      "1 - [\"Int'l Plan : no\"]\n",
      "2 - [\"Int'l Plan : no\", 'Intl Calls : 1.0']\n",
      "2 - ['CustServ Calls : 2.0', \"Int'l Plan : no\"]\n",
      "2 - [\"Int'l Plan : no\", 'Intl Calls : 2.0']\n",
      "2 - ['Area Code : 415', \"Int'l Plan : no\"]\n",
      "2 - [\"Int'l Plan : no\", 'VMail Message : 0']\n"
     ]
    }
   ],
   "source": [
    "false = TP(data=transaction_churn_false,s=freq_false,minSup=len(transaction_churn_false)*threshold)\n",
    "for (level, sub_list) in false.miningResults().items():\n",
    "    for each in sub_list:\n",
    "        print(f\"{level} - {each}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Churn is True**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Customers exhibit **high communication needs**, as indicated by the high duration and number of morning, evening, and international calls.\n",
    "\n",
    "- Despite the **high international call** duration, customers **do not sign up** for an international service package. This suggests potential dissatisfaction with the international service offering.\n",
    "\n",
    "- The presence of **high customer service call** frequency may reflect dissatisfaction with the service quality or other aspects of the telecommunications service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Churn is False**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a **tendency** to use services that involve **calls**, especially during the day.\n",
    "\n",
    "- The **low number of calls to customer service** may indicate they don't have many problems or have a positive attitude toward service.\n",
    "\n",
    "- **Less** likely to **sign up for an international plan**, suggesting they may not have a need or interest in international features."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Lab01 - Frequent itemset mining.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
